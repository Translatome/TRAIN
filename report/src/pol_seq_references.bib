@misc{allaire_rmarkdown_nodate,
  title  = {rmarkdown: {Dynamic} {Documents} for {R}},
  url    = {https://github.com/rstudio/rmarkdown},
  author = {Allaire, J.J. and et al.},
  year   = {2023},
  note   = {R package version 2.24}
}

@article{anders_htseqpython_2015,
  title    = {{HTSeq}—a {Python} framework to work with high-throughput sequencing data},
  volume   = {31},
  issn     = {1367-4811, 1367-4803},
  url      = {https://academic.oup.com/bioinformatics/article/31/2/166/2366196},
  doi      = {10.1093/bioinformatics/btu638},
  abstract = {Abstract 
              Motivation: A large choice of tools exists for many standard tasks in the analysis of high-throughput sequencing (HTS) data. However, once a project deviates from standard workflows, custom scripts are needed. 
              Results: We present HTSeq, a Python library to facilitate the rapid development of such scripts. HTSeq offers parsers for many common data formats in HTS projects, as well as classes to represent data, such as genomic coordinates, sequences, sequencing reads, alignments, gene model information and variant calls, and provides data structures that allow for querying via genomic coordinates. We also present htseq-count, a tool developed with HTSeq that preprocesses RNA-Seq data for differential expression analysis by counting the overlap of reads with genes. 
              Availability and implementation: HTSeq is released as an open-source software under the GNU General Public Licence and available from http://www-huber.embl.de/HTSeq or from the Python Package Index at https://pypi.python.org/pypi/HTSeq . 
              Contact:  sanders@fs.tum.de},
  language = {en},
  number   = {2},
  urldate  = {2023-05-02},
  journal  = {Bioinformatics},
  author   = {Anders, Simon and Pyl, Paul Theodor and Huber, Wolfgang},
  month    = jan,
  year     = {2015},
  pages    = {166--169}
}

@misc{noauthor_fastqc_nodate,
  title   = {{FastQC}: a quality control tool for high throughput sequence data – {ScienceOpen}},
  url     = {https://www.scienceopen.com/document?vid=de674375-ab83-4595-afa9-4c8aa9e4e736},
  urldate = {2023-05-02},
  author  = {Andrews, S.},
  place   = {Babraham, UK},
  company = {Babraham Institute},
  year    = {2010}
}

@misc{auguie_gridextra_2017,
  title      = {{gridExtra}: {Miscellaneous} {Functions} for "{Grid}" {Graphics}},
  copyright  = {GPL-2 {\textbar} GPL-3 [expanded from: GPL (≥ 2)]},
  shorttitle = {{gridExtra}},
  url        = {https://cran.r-project.org/web/packages/gridExtra/index.html},
  abstract   = {Provides a number of user-level functions to work with "grid" graphics, notably to arrange multiple grid-based plots on a page, and draw tables.},
  urldate    = {2023-05-09},
  author     = {Auguie, Baptiste and Antonov, Anton},
  month      = sep,
  year       = {2017}
}

@article{bushnell_bbmap_2014,
  title      = {{BBMap}: A Fast, Accurate, Splice-Aware Aligner},
  url        = {https://escholarship.org/uc/item/1h3515gn},
  shorttitle = {{BBMap}},
  abstract   = {Alignment of reads is one of the primary computational tasks in bioinformatics. Of paramount importance to resequencing, alignment is also crucial to other areas - quality control, scaffolding, string-graph assembly, homology detection, assembly evaluation, error-correction, expression quantification, and even as a tool to evaluate other tools. An optimal aligner would greatly improve virtually any sequencing process, but optimal alignment is prohibitively expensive for gigabases of data. Here, we will present {BBMap} [1], a fast splice-aware aligner for short and long reads. We will demonstrate that {BBMap} has superior speed, sensitivity, and specificity to alternative high-throughput aligners bowtie2 [2], bwa [3], smalt, [4] {GSNAP} [5], and {BLASR} [6].},
  journal    = {Conference: 9th Annual Genomics of Energy \& Environment Meeting, Walnut Creek, {CA}, March 17-20, 2014},
  author     = {Bushnell, Brian},
  urldate    = {2023-05-02},
  year       = {2014},
  langid     = {english}
}

@article{chen_fastp_2018,
  title      = {fastp: an ultra-fast all-in-one {FASTQ} preprocessor},
  volume     = {34},
  issn       = {1367-4803, 1460-2059},
  shorttitle = {fastp},
  url        = {https://academic.oup.com/bioinformatics/article/34/17/i884/5093234},
  doi        = {10.1093/bioinformatics/bty560},
  language   = {en},
  number     = {17},
  urldate    = {2023-05-02},
  journal    = {Bioinformatics},
  author     = {Chen, Shifu and Zhou, Yanqing and Chen, Yaru and Gu, Jia},
  month      = sep,
  year       = {2018},
  pages      = {i884--i890}
}

@article{chen_reads_2016,
  title      = {From reads to genes to pathways: differential expression analysis of {RNA}-{Seq} experiments using {Rsubread} and the {edgeR} quasi-likelihood pipeline},
  volume     = {5},
  issn       = {2046-1402},
  shorttitle = {From reads to genes to pathways},
  url        = {https://f1000research.com/articles/5-1438/v2},
  doi        = {10.12688/f1000research.8987.2},
  abstract   = {In recent years, RNA sequencing (RNA-seq) has become a very widely used technology for profiling gene expression. One of the most common aims of RNA-seq profiling is to identify genes or molecular pathways that are differentially expressed (DE) between two or more biological conditions. This article demonstrates a computational workflow for the detection of DE genes and pathways from RNA-seq data by providing a complete analysis of an RNA-seq experiment profiling epithelial cell subsets in the mouse mammary gland. The workflow uses R software packages from the open-source Bioconductor project and covers all steps of the analysis pipeline, including alignment of read sequences, data exploration, differential expression analysis, visualization and pathway analysis. Read alignment and count quantification is conducted using the Rsubread package and the statistical analyses are performed using the edgeR package. The differential expression analysis uses the quasi-likelihood functionality of edgeR.},
  language   = {en},
  urldate    = {2023-05-09},
  journal    = {F1000Research},
  author     = {Chen, Yunshun and Lun, Aaron T. L. and Smyth, Gordon K.},
  month      = aug,
  year       = {2016},
  pages      = {1438}
}

@misc{daroczi_pander_2022,
  title      = {pander: {An} {R} '{Pandoc}' {Writer}},
  copyright  = {AGPL-3 {\textbar} file LICENSE},
  shorttitle = {pander},
  url        = {https://cran.r-project.org/web/packages/pander/index.html},
  abstract   = {Contains some functions catching all messages, 'stdout' and other useful information while evaluating R code and other helpers to return user specified text elements (like: header, paragraph, table, image, lists etc.) in 'pandoc' markdown or several type of R objects similarly automatically transformed to markdown format. Also capable of exporting/converting (the resulting) complex 'pandoc' documents to e.g. HTML, 'PDF', 'docx' or 'odt'. This latter reporting feature is supported in brew syntax or with a custom reference class with a smarty caching 'backend'.},
  urldate    = {2023-05-09},
  author     = {Daróczi, Gergely and Tsegelskyi, Roman},
  month      = mar,
  year       = {2022},
  keywords   = {ReproducibleResearch}
}

@article{dobin_star_2013,
  title      = {{STAR}: ultrafast universal {RNA}-seq aligner},
  volume     = {29},
  issn       = {1367-4811, 1367-4803},
  shorttitle = {{STAR}},
  url        = {https://academic.oup.com/bioinformatics/article/29/1/15/272537},
  doi        = {10.1093/bioinformatics/bts635},
  abstract   = {Abstract 
                Motivation: Accurate alignment of high-throughput RNA-seq data is a challenging and yet unsolved problem because of the non-contiguous transcript structure, relatively short read lengths and constantly increasing throughput of the sequencing technologies. Currently available RNA-seq aligners suffer from high mapping error rates, low mapping speed, read length limitation and mapping biases. 
                Results: To align our large (\&gt;80 billon reads) ENCODE Transcriptome RNA-seq dataset, we developed the Spliced Transcripts Alignment to a Reference (STAR) software based on a previously undescribed RNA-seq alignment algorithm that uses sequential maximum mappable seed search in uncompressed suffix arrays followed by seed clustering and stitching procedure. STAR outperforms other aligners by a factor of \&gt;50 in mapping speed, aligning to the human genome 550 million 2 × 76 bp paired-end reads per hour on a modest 12-core server, while at the same time improving alignment sensitivity and precision. In addition to unbiased de novo detection of canonical junctions, STAR can discover non-canonical splices and chimeric (fusion) transcripts, and is also capable of mapping full-length RNA sequences. Using Roche 454 sequencing of reverse transcription polymerase chain reaction amplicons, we experimentally validated 1960 novel intergenic splice junctions with an 80–90\% success rate, corroborating the high precision of the STAR mapping strategy. 
                Availability and implementation: STAR is implemented as a standalone C++ code. STAR is free open source software distributed under GPLv3 license and can be downloaded from http://code.google.com/p/rna-star/. 
                Contact: dobin@cshl.edu.},
  language   = {en},
  number     = {1},
  urldate    = {2023-05-02},
  journal    = {Bioinformatics},
  author     = {Dobin, Alexander and et al.},
  month      = jan,
  year       = {2013},
  pages      = {15--21}
}

@misc{dowle_datatable_2023,
  title      = {data.table: {Extension} of 'data.frame'},
  copyright  = {MPL-2.0 {\textbar} file LICENSE},
  shorttitle = {data.table},
  url        = {https://cran.r-project.org/web/packages/data.table/index.html},
  abstract   = {Fast aggregation of large data (e.g. 100GB in RAM), fast ordered joins, fast add/modify/delete of columns by group using no copies at all, list columns, friendly and fast character-separated-value read/write. Offers a natural and flexible syntax, for faster development.},
  urldate    = {2023-05-09},
  author     = {Dowle, Matt and et al.},
  month      = feb,
  year       = {2023},
  keywords   = {Finance, HighPerformanceComputing, TimeSeries, WebTechnologies}
}

@article{ewels_multiqc_2016,
  title      = {{MultiQC}: summarize analysis results for multiple tools and samples in a single report},
  volume     = {32},
  issn       = {1367-4811, 1367-4803},
  shorttitle = {{MultiQC}},
  url        = {https://academic.oup.com/bioinformatics/article/32/19/3047/2196507},
  doi        = {10.1093/bioinformatics/btw354},
  abstract   = {Abstract 
                Motivation: Fast and accurate quality control is essential for studies involving next-generation sequencing data. Whilst numerous tools exist to quantify QC metrics, there is no common approach to flexibly integrate these across tools and large sample sets. Assessing analysis results across an entire project can be time consuming and error prone; batch effects and outlier samples can easily be missed in the early stages of analysis. 
                Results: We present MultiQC, a tool to create a single report visualising output from multiple tools across many samples, enabling global trends and biases to be quickly identified. MultiQC can plot data from many common bioinformatics tools and is built to allow easy extension and customization. 
                Availability and implementation: MultiQC is available with an GNU GPLv3 license on GitHub, the Python Package Index and Bioconda. Documentation and example reports are available at http://multiqc.info 
                Contact:  phil.ewels@scilifelab.se},
  language   = {en},
  number     = {19},
  urldate    = {2023-05-02},
  journal    = {Bioinformatics},
  author     = {Ewels, Philip and Magnusson, Måns and Lundin, Sverker and Käller, Max},
  month      = oct,
  year       = {2016},
  pages      = {3047--3048}
}

@article{klopfenstein_goatools_2018,
  title      = {{GOATOOLS}: {A} {Python} library for {Gene} {Ontology} analyses},
  volume     = {8},
  copyright  = {2018 The Author(s)},
  issn       = {2045-2322},
  shorttitle = {{GOATOOLS}},
  url        = {https://www.nature.com/articles/s41598-018-28948-z},
  doi        = {10.1038/s41598-018-28948-z},
  abstract   = {The biological interpretation of gene lists with interesting shared properties, such as up- or down-regulation in a particular experiment, is typically accomplished using gene ontology enrichment analysis tools. Given a list of genes, a gene ontology (GO) enrichment analysis may return hundreds of statistically significant GO results in a “flat” list, which can be challenging to summarize. It can also be difficult to keep pace with rapidly expanding biological knowledge, which often results in daily changes to any of the over 47,000 gene ontologies that describe biological knowledge. GOATOOLS, a Python-based library, makes it more efficient to stay current with the latest ontologies and annotations, perform gene ontology enrichment analyses to determine over- and under-represented terms, and organize results for greater clarity and easier interpretation using a novel GOATOOLS GO grouping method. We performed functional analyses on both stochastic simulation data and real data from a published RNA-seq study to compare the enrichment results from GOATOOLS to two other popular tools: DAVID and GOstats. GOATOOLS is freely available through GitHub: https://github.com/tanghaibao/goatools.},
  language   = {en},
  number     = {1},
  urldate    = {2023-05-02},
  journal    = {Scientific Reports},
  author     = {Klopfenstein, D. V. and et al.},
  month      = jul,
  year       = {2018},
  keywords   = {Gene ontology, Software},
  pages      = {10872}
}

@article{kolberg_gprofiler2_2020,
  title      = {gprofiler2 -- an {R} package for gene list functional enrichment analysis and namespace conversion toolset g:{Profiler}},
  volume     = {9},
  issn       = {2046-1402},
  shorttitle = {gprofiler2 -- an {R} package for gene list functional enrichment analysis and namespace conversion toolset g},
  url        = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7859841/},
  doi        = {10.12688/f1000research.24956.2},
  abstract   = {g:Profiler (
                https://biit.cs.ut.ee/gprofiler) is a widely used gene list functional profiling and namespace conversion toolset that has been contributing to reproducible biological data analysis already since 2007. Here we introduce the accompanying R package,
                gprofiler2, developed to facilitate programmatic access to g:Profiler computations and databases via REST API. The
                gprofiler2 package provides an easy-to-use functionality that enables researchers to incorporate functional enrichment analysis into automated analysis pipelines written in R. The package also implements interactive visualisation methods to help to interpret the enrichment results and to illustrate them for publications. In addition,
                gprofiler2 gives access to the versatile gene/protein identifier conversion functionality in g:Profiler enabling to map between hundreds of different identifier types or orthologous species. The
                gprofiler2 package is freely available at the
                CRAN repository.},
  urldate    = {2023-05-02},
  journal    = {F1000Research},
  author     = {Kolberg, Liis and et al.},
  month      = nov,
  year       = {2020},
  pmid       = {33564394},
  pmcid      = {PMC7859841},
  pages      = {ELIXIR--709}
}

@article{law_voom_2014,
  title      = {voom: precision weights unlock linear model analysis tools for {RNA}-seq read counts},
  volume     = {15},
  issn       = {1474-760X},
  shorttitle = {voom},
  url        = {https://doi.org/10.1186/gb-2014-15-2-r29},
  doi        = {10.1186/gb-2014-15-2-r29},
  abstract   = {New normal linear modeling strategies are presented for analyzing read counts from RNA-seq experiments. The voom method estimates the mean-variance relationship of the log-counts, generates a precision weight for each observation and enters these into the limma empirical Bayes analysis pipeline. This opens access for RNA-seq analysts to a large body of methodology developed for microarrays. Simulation studies show that voom performs as well or better than count-based RNA-seq methods even when the data are generated according to the assumptions of the earlier methods. Two case studies illustrate the use of linear modeling and gene set testing methods.},
  number     = {2},
  urldate    = {2023-05-02},
  journal    = {Genome Biology},
  author     = {Law, Charity W. and Chen, Yunshun and Shi, Wei and Smyth, Gordon K.},
  month      = feb,
  year       = {2014},
  keywords   = {Differentially Express, Error Rate Control, Library Size, Negative Binomial, Precision Weight},
  pages      = {R29}
}

@article{li_sequence_2009,
  title    = {The {Sequence} {Alignment}/{Map} format and {SAMtools}},
  volume   = {25},
  issn     = {1367-4811, 1367-4803},
  url      = {https://academic.oup.com/bioinformatics/article/25/16/2078/204688},
  doi      = {10.1093/bioinformatics/btp352},
  abstract = {Abstract 
              Summary: The Sequence Alignment/Map (SAM) format is a generic alignment format for storing read alignments against reference sequences, supporting short and long reads (up to 128 Mbp) produced by different sequencing platforms. It is flexible in style, compact in size, efficient in random access and is the format in which alignments from the 1000 Genomes Project are released. SAMtools implements various utilities for post-processing alignments in the SAM format, such as indexing, variant caller and alignment viewer, and thus provides universal tools for processing read alignments. 
              Availability:  http://samtools.sourceforge.net 
              Contact:  rd@sanger.ac.uk},
  language = {en},
  number   = {16},
  urldate  = {2023-05-02},
  journal  = {Bioinformatics},
  author   = {Li, Heng and et al.},
  month    = aug,
  year     = {2009},
  pages    = {2078--2079}
}

@article{liao_featurecounts_2014,
  title      = {{featureCounts}: an efficient general purpose program for assigning sequence reads to genomic features},
  volume     = {30},
  issn       = {1367-4811, 1367-4803},
  shorttitle = {{featureCounts}},
  url        = {https://academic.oup.com/bioinformatics/article/30/7/923/232889},
  doi        = {10.1093/bioinformatics/btt656},
  abstract   = {Abstract 
                Motivation: Next-generation sequencing technologies generate millions of short sequence reads, which are usually aligned to a reference genome. In many applications, the key information required for downstream analysis is the number of reads mapping to each genomic feature, for example to each exon or each gene. The process of counting reads is called read summarization. Read summarization is required for a great variety of genomic analyses but has so far received relatively little attention in the literature. 
                Results: We present featureCounts, a read summarization program suitable for counting reads generated from either RNA or genomic DNA sequencing experiments. featureCounts implements highly efficient chromosome hashing and feature blocking techniques. It is considerably faster than existing methods (by an order of magnitude for gene-level summarization) and requires far less computer memory. It works with either single or paired-end reads and provides a wide range of options appropriate for different sequencing applications. 
                Availability and implementation:   featureCounts is available under GNU General Public License as part of the Subread (http://subread.sourceforge.net) or Rsubread (http://www.bioconductor.org) software packages. 
                Contact:   shi@wehi.edu.au},
  language   = {en},
  number     = {7},
  urldate    = {2023-05-02},
  journal    = {Bioinformatics},
  author     = {Liao, Yang and Smyth, Gordon K. and Shi, Wei},
  month      = apr,
  year       = {2014},
  pages      = {923--930}
}

@article{liao_r_2019,
  title    = {The {R} package {Rsubread} is easier, faster, cheaper and better for alignment and quantification of {RNA} sequencing reads},
  volume   = {47},
  issn     = {0305-1048, 1362-4962},
  url      = {https://academic.oup.com/nar/article/47/8/e47/5345150},
  doi      = {10.1093/nar/gkz114},
  language = {en},
  number   = {8},
  urldate  = {2023-07-19},
  journal  = {Nucleic Acids Research},
  author   = {Liao, Yang and Smyth, Gordon K and Shi, Wei},
  month    = may,
  year     = {2019},
  pages    = {e47--e47}
}

@article{love_moderated_2014,
  title    = {Moderated estimation of fold change and dispersion for {RNA}-seq data with {DESeq2}},
  volume   = {15},
  issn     = {1474-760X},
  url      = {https://doi.org/10.1186/s13059-014-0550-8},
  doi      = {10.1186/s13059-014-0550-8},
  abstract = {In comparative high-throughput sequencing assays, a fundamental task is the analysis of count data, such as read counts per gene in RNA-seq, for evidence of systematic changes across experimental conditions. Small replicate numbers, discreteness, large dynamic range and the presence of outliers require a suitable statistical approach. We present DESeq2, a method for differential analysis of count data, using shrinkage estimation for dispersions and fold changes to improve stability and interpretability of estimates. This enables a more quantitative analysis focused on the strength rather than the mere presence of differential expression. The DESeq2 package is available at http://www.bioconductor.org/packages/release/bioc/html/DESeq2.html.},
  number   = {12},
  urldate  = {2023-05-02},
  journal  = {Genome Biology},
  author   = {Love, Michael I. and Huber, Wolfgang and Anders, Simon},
  month    = dec,
  year     = {2014},
  keywords = {DESeq2 Package, Differential Expression Analysis, Negative Binomial Generalize Linear Model, Observe Fisher Information, Read Count},
  pages    = {550}
}

@article{martens_wikipathways_2021,
  title      = {{WikiPathways}: connecting communities},
  volume     = {49},
  issn       = {0305-1048, 1362-4962},
  shorttitle = {{WikiPathways}},
  url        = {https://academic.oup.com/nar/article/49/D1/D613/5992285},
  doi        = {10.1093/nar/gkaa1024},
  abstract   = {Abstract 
                WikiPathways (https://www.wikipathways.org) is a biological pathway database known for its collaborative nature and open science approaches. With the core idea of the scientific community developing and curating biological knowledge in pathway models, WikiPathways lowers all barriers for accessing and using its content. Increasingly more content creators, initiatives, projects and tools have started using WikiPathways. Central in this growth and increased use of WikiPathways are the various communities that focus on particular subsets of molecular pathways such as for rare diseases and lipid metabolism. Knowledge from published pathway figures helps prioritize pathway development, using optical character and named entity recognition. We show the growth of WikiPathways over the last three years, highlight the new communities and collaborations of pathway authors and curators, and describe various technologies to connect to external resources and initiatives. The road toward a sustainable, community-driven pathway database goes through integration with other resources such as Wikidata and allowing more use, curation and redistribution of WikiPathways content.},
  language   = {en},
  number     = {D1},
  urldate    = {2023-07-19},
  journal    = {Nucleic Acids Research},
  author     = {Martens, Marvin and et al.},
  month      = jan,
  year       = {2021},
  pages      = {D613--D621}
}

@article{martin_cutadapt_2011,
  title     = {Cutadapt removes adapter sequences from high-throughput sequencing reads},
  volume    = {17},
  copyright = {Copyright (c)},
  issn      = {2226-6089},
  url       = {https://journal.embnet.org/index.php/embnetjournal/article/view/200},
  doi       = {10.14806/ej.17.1.200},
  abstract  = {When small RNA is sequenced on current sequencing machines, the resulting reads are usually longer than the RNA and therefore contain parts of the 3' adapter. That adapter must be found and removed error-tolerantly from each read before read mapping. Previous solutions are either hard to use or do not offer required features, in particular support for color space data. As an easy to use alternative, we developed the command-line tool cutadapt, which supports 454, Illumina and SOLiD (color space) data, offers two adapter trimming algorithms, and has other useful features. Cutadapt, including its MIT-licensed source code, is available for download at http://code.google.com/p/cutadapt/},
  language  = {en},
  number    = {1},
  urldate   = {2023-05-02},
  journal   = {EMBnet.journal},
  author    = {Martin, Marcel},
  month     = may,
  year      = {2011},
  keywords  = {adapter removal, microRNA, next generation sequencing, small RNA},
  pages     = {10--12}
}

@article{mccarthy_differential_2012,
  title    = {Differential expression analysis of multifactor {RNA}-{Seq} experiments with respect to biological variation},
  volume   = {40},
  issn     = {1362-4962, 0305-1048},
  url      = {https://academic.oup.com/nar/article/40/10/4288/2411520},
  doi      = {10.1093/nar/gks042},
  language = {en},
  number   = {10},
  urldate  = {2023-05-09},
  journal  = {Nucleic Acids Research},
  author   = {McCarthy, Davis J. and Chen, Yunshun and Smyth, Gordon K.},
  month    = may,
  year     = {2012},
  pages    = {4288--4297}
}

@book{mckinney_wes_data_2010,
  edition   = {Stefan van der Walt and Jarrod Millman},
  title     = {Data {Structures} for {Statistical} {Computing} in {Python}},
  publisher = {Proceedings of the 9th Python in Science Conference},
  author    = {McKinney, Wes},
  year      = {2010}
}

@article{molder_sustainable_2021,
  title    = {Sustainable data analysis with {Snakemake}},
  volume   = {10},
  issn     = {2046-1402},
  url      = {https://f1000research.com/articles/10-33/v2},
  doi      = {10.12688/f1000research.29032.2},
  abstract = {Data analysis often entails a multitude of heterogeneous steps, from the application of various command line tools to the usage of scripting languages like R or Python for the generation of plots and tables. It is widely recognized that data analyses should ideally be conducted in a reproducible way. Reproducibility enables technical validation and regeneration of results on the original or even new data. However, reproducibility alone is by no means sufficient to deliver an analysis that is of lasting impact (i.e., sustainable) for the field, or even just one research group. We postulate that it is equally important to ensure adaptability and transparency. The former describes the ability to modify the analysis to answer extended or slightly different research questions. The latter describes the ability to understand the analysis in order to judge whether it is not only technically, but methodologically valid. 
              Here, we analyze the properties needed for a data analysis to become reproducible, adaptable, and transparent. We show how the popular workflow management system Snakemake can be used to guarantee this, and how it enables an ergonomic, combined, unified representation of all steps involved in data analysis, ranging from raw data processing, to quality control and fine-grained, interactive exploration and plotting of final results.},
  language = {en},
  urldate  = {2023-05-09},
  journal  = {F1000Research},
  author   = {Mölder, Felix and et al.},
  month    = apr,
  year     = {2021},
  pages    = {33}
}

@article{mudunuri_biodbnet_2009,
  title      = {{bioDBnet}: the biological database network},
  volume     = {25},
  issn       = {1367-4811, 1367-4803},
  shorttitle = {{bioDBnet}},
  url        = {https://academic.oup.com/bioinformatics/article/25/4/555/249696},
  doi        = {10.1093/bioinformatics/btn654},
  abstract   = {Abstract 
                Summary: bioDBnet is an online web resource that provides interconnected access to many types of biological databases. It has integrated many of the most commonly used biological databases and in its current state has 153 database identifiers (nodes) covering all aspects of biology including genes, proteins, pathways and other biological concepts. bioDBnet offers various ways to work with these databases including conversions, extensive database reports, custom navigation and has various tools to enhance the quality of the results. Importantly, the access to bioDBnet is updated regularly, providing access to the most recent releases of each individual database. 
                Availability:  http://biodbnet.abcc.ncifcrf.gov 
                Contact:  stephensr@mail.nih.gov 
                Supplementary information:  Supplementary data are available at Bioinformatics online},
  language   = {en},
  number     = {4},
  urldate    = {2023-05-02},
  journal    = {Bioinformatics},
  author     = {Mudunuri, Uma and Che, Anney and Yi, Ming and Stephens, Robert M.},
  month      = feb,
  year       = {2009},
  pages      = {555--556}
}

@article{ritchie_limma_2015,
  title    = {limma powers differential expression analyses for {RNA}-sequencing and microarray studies},
  volume   = {43},
  issn     = {1362-4962, 0305-1048},
  url      = {http://academic.oup.com/nar/article/43/7/e47/2414268/limma-powers-differential-expression-analyses-for},
  doi      = {10.1093/nar/gkv007},
  language = {en},
  number   = {7},
  urldate  = {2023-05-09},
  journal  = {Nucleic Acids Research},
  author   = {Ritchie, Matthew E. and et al.},
  month    = apr,
  year     = {2015},
  pages    = {e47--e47}
}

@article{waskom_seaborn_2021,
  title      = {seaborn: statistical data visualization},
  volume     = {6},
  issn       = {2475-9066},
  shorttitle = {seaborn},
  url        = {https://joss.theoj.org/papers/10.21105/joss.03021},
  doi        = {10.21105/joss.03021},
  number     = {60},
  urldate    = {2023-05-09},
  journal    = {Journal of Open Source Software},
  author     = {Waskom, Michael},
  month      = apr,
  year       = {2021},
  pages      = {3021}
}

@article{wickham_split-apply-combine_2011,
  title     = {The {Split}-{Apply}-{Combine} {Strategy} for {Data} {Analysis}},
  volume    = {40},
  copyright = {Copyright (c) 2009 Hadley  Wickham},
  issn      = {1548-7660},
  url       = {https://doi.org/10.18637/jss.v040.i01},
  doi       = {10.18637/jss.v040.i01},
  abstract  = {Many data analysis problems involve the application of a split-apply-combine strategy, where you break up a big problem into manageable pieces, operate on each piece independently and then put all the pieces back together. This insight gives rise to a new R package that allows you to smoothly apply this strategy, without having to worry about the type of structure in which your data is stored.
               
               The paper includes two case studies showing how these insights make it easier to work with batting records for veteran baseball players and a large 3d array of spatio-temporal ozone measurements.},
  language  = {en},
  urldate   = {2023-05-09},
  journal   = {Journal of Statistical Software},
  author    = {Wickham, Hadley},
  month     = apr,
  year      = {2011},
  pages     = {1--29}
}

@misc{wickham_hadley_ggplot2_2016,
  title     = {ggplot2: {Elegant} {Graphics} for {Data} {Analysis}.},
  url       = {https://ggplot2.tidyverse.org},
  urldate   = {2023-05-02},
  publisher = {Springer-Verlag New York},
  author    = {Wickham, Hadley.},
  year      = {2016}
}

@misc{wickham_scales_2022,
  title      = {scales: {Scale} {Functions} for {Visualization}},
  copyright  = {MIT + file LICENSE},
  shorttitle = {scales},
  url        = {https://cran.r-project.org/web/packages/scales/index.html},
  abstract   = {Graphical scales map data to aesthetics, and provide methods for automatically determining breaks and labels for axes and legends.},
  urldate    = {2023-05-09},
  author     = {Wickham, Hadley and Seidel, Dana},
  month      = aug,
  year       = {2022}
}

@article{wingett_fastq_2018,
  title      = {{FastQ} {Screen}: {A} tool for multi-genome mapping and quality control},
  volume     = {7},
  issn       = {2046-1402},
  shorttitle = {{FastQ} {Screen}},
  url        = {https://f1000research.com/articles/7-1338/v2},
  doi        = {10.12688/f1000research.15931.2},
  abstract   = {DNA sequencing analysis typically involves mapping reads to just one reference genome. Mapping against multiple genomes is necessary, however, when the genome of origin requires confirmation. Mapping against multiple genomes is also advisable for detecting contamination or for identifying sample swaps which, if left undetected, may lead to incorrect experimental conclusions. Consequently, we present FastQ Screen, a tool to validate the origin of DNA samples by quantifying the proportion of reads that map to a panel of reference genomes. FastQ Screen is intended to be used routinely as a quality control measure and for analysing samples in which the origin of the DNA is uncertain or has multiple sources.},
  language   = {en},
  urldate    = {2023-05-02},
  journal    = {F1000Research},
  author     = {Wingett, Steven W. and Andrews, Simon},
  month      = sep,
  year       = {2018},
  pages      = {1338}
}

@book{grolemund_r_nodate,
  title      = {R {Markdown}: {The} {Definitive} {Guide}},
  shorttitle = {R {Markdown}},
  url        = {https://bookdown.org/yihui/rmarkdown/},
  abstract   = {The first official book authored by the core R Markdown developers that provides a comprehensive and accurate reference to the R Markdown ecosystem. With R Markdown, you can easily create reproducible data analysis reports, presentations, dashboards, interactive applications, books, dissertations, websites, and journal articles, while enjoying the simplicity of Markdown and the great power of R and other languages.},
  urldate    = {2023-05-09},
  author     = {Xie, Yihui and Allaire, J. J. and Grolemund, Garrett},
  publisher  = {Chapman and Hall/CRC},
  address    = {Boca Raton, Florida},
  year       = {2018},
  isbn       = {9781138359338}
}

@book{riederer_r_nodate,
  title     = {R {Markdown} {Cookbook}},
  url       = {https://bookdown.org/yihui/rmarkdown-cookbook/},
  abstract  = {This book showcases short, practical examples of lesser-known tips and tricks to helps users get the most out of these tools. After reading this book, you will understand how R Markdown documents are transformed from plain text and how you may customize nearly every step of this processing. For example, you will learn how to dynamically create content from R code, reference code in other documents or chunks, control the formatting with customer templates, fine-tune how your code is processed, and incorporate multiple languages into your analysis.},
  urldate   = {2023-05-09},
  author    = {Xie, Yihui and Dervieux, Christophe and Riederer, Emily},
  publisher = {Chapman and Hall/CRC},
  address   = {Boca Raton, Florida},
  year      = {2020},
  isbn      = {9780367563837}
}

@article{yates_ensembl_2020,
  title    = {Ensembl 2020},
  volume   = {48},
  issn     = {0305-1048},
  url      = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7145704/},
  doi      = {10.1093/nar/gkz966},
  abstract = {The Ensembl (https://www.ensembl.org) is a system for generating and distributing genome annotation such as genes, variation, regulation and comparative genomics across the vertebrate subphylum and key model organisms. The Ensembl annotation pipeline is capable of integrating experimental and reference data from multiple providers into a single integrated resource. Here, we present 94 newly annotated and re-annotated genomes, bringing the total number of genomes offered by Ensembl to 227. This represents the single largest expansion of the resource since its inception. We also detail our continued efforts to improve human annotation, developments in our epigenome analysis and display, a new tool for imputing causal genes from genome-wide association studies and visualisation of variation within a 3D protein model. Finally, we present information on our new website. Both software and data are made available without restriction via our website, online tools platform and programmatic interfaces (available under an Apache 2.0 license) and data updates made available four times a year.},
  number   = {D1},
  urldate  = {2023-05-02},
  journal  = {Nucleic Acids Research},
  author   = {Yates, Andrew D and et al.},
  month    = jan,
  year     = {2020},
  pmid     = {31691826},
  pmcid    = {PMC7145704},
  pages    = {D682--D688}
}

@misc{zhu_kableextra_2021,
  title      = {{kableExtra}: {Construct} {Complex} {Table} with 'kable' and {Pipe} {Syntax}},
  copyright  = {MIT + file LICENSE},
  shorttitle = {{kableExtra}},
  url        = {https://cran.r-project.org/web/packages/kableExtra/index.html},
  abstract   = {Build complex HTML or 'LaTeX' tables using 'kable()' from 'knitr' and the piping syntax from 'magrittr'. Function 'kable()' is a light weight table generator coming from 'knitr'. This package simplifies the way to manipulate the HTML or 'LaTeX' codes generated by 'kable()' and allows users to construct complex tables and customize styles using a readable syntax.},
  urldate    = {2023-05-09},
  author     = {Zhu, Hao and et al.},
  month      = feb,
  year       = {2021}
}

